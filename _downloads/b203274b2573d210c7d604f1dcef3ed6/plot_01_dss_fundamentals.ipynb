{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fundamentals of DSS.\n\nThis tutorial introduces **Denoising Source Separation (DSS)**, a technique for\nextracting brain sources based on a specific criterion of \"interestingness\" (bias).\n\nUnlike PCA, which finds components of high *variance*, or ICA, which finds components\nof high *non-Gaussianity*, DSS finds components that maximize a user-defined **Bias**.\n\nThe core optimization is:\n\n\\begin{align}\\\\max_w \\\\frac{w^T R_{biased} w}{w^T R_{baseline} w}\\end{align}\n\nwhere:\n*   $R_{biased}$ is the covariance of the \"signal of interest\" (biased data).\n*   $R_{baseline}$ is the covariance of the raw data (or noise).\n\nThis allows DSS to be extremely flexible. The \"Bias\" defines what you are looking for.\nTypical biases include:\n*   **Trial Averaging**: Finds stimulus-evoked responses (reproducible across trials).\n*   **Bandpass Filtering**: Finds oscillatory sources (alpha, beta, etc.).\n*   **Time Masking**: Finds artifacts (blinks, heartbeats) to remove them.\n\nThis tutorial demonstrates the \"Hello World\" of DSS: extracting a repetitive signal\nburied in noise using the **Trial Average Bias**.\n\nAuthors: Sina Esmaeili (sina.esmaeili@umontreal.ca)\n         Hamza Abdelhedi (hamza.abdelhedi@umontreal.ca)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import contextlib\nimport os\n\nimport mne\nimport numpy as np\nfrom mne.datasets import sample\n\nfrom mne_denoise.dss import DSS, AverageBias, BandpassBias\nfrom mne_denoise.viz import (\n    plot_component_summary,\n    plot_component_time_series,\n    plot_evoked_comparison,\n    plot_psd_comparison,\n    plot_score_curve,\n    plot_spatial_patterns,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Synthetic Data\nWe generate synthetic data with distinct components to demonstrate different biases.\n*   **Signal A (Evoked)**: 10 Hz sine wave, phase-locked (reproducible).\n*   **Signal B (Oscillatory)**: 50 Hz, random phase (not reproducible, but distinct frequency).\n*   **Noise**: White noise.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Generating synthetic data...\")\nn_epochs = 50\nn_times = 500\nn_channels = 32\nsfreq = 250\n\ntimes = np.arange(n_times) / sfreq\ndata = np.zeros((n_epochs, n_channels, n_times))\n\n# Create standard montage for realistic topomaps\nmontage = mne.channels.make_standard_montage(\"standard_1020\")\nch_names = montage.ch_names[:n_channels]\ninfo = mne.create_info(ch_names, sfreq, \"eeg\")\ninfo.set_montage(montage)\n\n# Generate smooth spatial patterns (dipole-like)\n# This fixes the \"noisy topomap\" issue by ensuring adjacent sensors have similar weights.\npos = np.array([ch[\"loc\"][:3] for ch in info[\"chs\"]])\ncenter_head = np.mean(pos, axis=0)\n\n# Pattern 1: Left-ish\ntarget_pos_1 = center_head + np.array([-0.05, 0, 0])\ndists_1 = np.linalg.norm(pos - target_pos_1, axis=1)\nmixing_evoked = np.exp(-(dists_1**2) / 0.02)\nmixing_evoked /= np.linalg.norm(mixing_evoked)\n\n# Pattern 2: Right-ish\ntarget_pos_2 = center_head + np.array([0.05, 0, 0.05])\ndists_2 = np.linalg.norm(pos - target_pos_2, axis=1)\nmixing_osc = np.exp(-(dists_2**2) / 0.02)\nmixing_osc /= np.linalg.norm(mixing_osc)\n\nrng = np.random.default_rng(42)\n\n# Generate spatially correlated noise (Background Activity)\n# Random dipoles to ensure noise has smooth topography (like real brain data)\nn_noise_sources = 20\nnoise_mix = np.zeros((n_channels, n_noise_sources))\nfor k in range(n_noise_sources):\n    # Random target position\n    rand_pos = center_head + rng.uniform(-0.06, 0.06, 3)\n    dists = np.linalg.norm(pos - rand_pos, axis=1)\n    # Smooth spatial field\n    field = np.exp(-(dists**2) / 0.015)\n    noise_mix[:, k] = field / np.linalg.norm(field)\n\nfor i in range(n_epochs):\n    # 1. Evoked Signal (10 Hz, reproducible)\n    signal_evoked = np.sin(2 * np.pi * 10 * times) * 2.0\n\n    # 2. Oscillatory interference (50 Hz, random phase)\n    # We also give this a smooth topography (Oscillator pattern)\n    phase = rng.uniform(0, 2 * np.pi)\n    signal_osc = np.sin(2 * np.pi * 50 * times + phase) * 1.5\n\n    # 3. Background Brain Noise (Spatially Smooth)\n    noise_src = rng.standard_normal((n_noise_sources, n_times))\n    brain_noise = noise_mix @ noise_src * 0.5\n\n    # 4. Sensor Noise (White, small)\n    sensor_noise = rng.standard_normal((n_channels, n_times)) * 0.1\n\n    # Combine\n    data[i] = (\n        np.outer(mixing_evoked, signal_evoked)\n        + np.outer(mixing_osc, signal_osc)\n        + brain_noise\n        + sensor_noise\n    )\n\nepochs = mne.EpochsArray(data, info)\nprint(f\"Created epochs: {epochs.get_data().shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Synthetic A: Trial Average Bias\nGoal: Isolate the **Evoked (10Hz)** component.\nBias: Maximize power of the mean over epochs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Synthetic: Trial Average Bias ---\")\ndss_evoked = DSS(n_components=3, bias=AverageBias(), return_type=\"sources\")\ndss_evoked.fit(epochs)\n\n# Visualize\n# 1. Score Curve\n# --------------\n# This plot shows the \"Bias Ratio\" for each component.\n# *   **Expectation**: The first component (Comp 0) should have a much higher score than the rest.\n# *   This indicates that Comp 0 is highly reproducible (signal), while others are noise.\nplot_score_curve(dss_evoked, mode=\"ratio\", show=False)\n\n# 2. Component Time Series\n# ------------------------\n# We view the time courses of the first 5 components.\n# *   **Expectation**: Comp 0 should look like a clean 10 Hz sine wave.\n# *   **Expectation**: Comp 1-4 should look like noise or the 50 Hz interference.\nplot_component_time_series(dss_evoked, data=epochs, n_components=3, show=False)\n\n# 3. Spatial Patterns\n# -------------------\n# The \"Spatial Pattern\" (or topomap) shows how the component maps onto the sensors.\n#\n# *   **Interpretation**:\n#     *   **Colors**: Red/Blue indicate opposite polarity. Strong colors mean the component\n#         is strongly present on those sensors.\n#     *   **Dots**: These represent the 32 electrodes of the 'standard_1020' montage.\n#     *   **Comp 0**: Shows a smooth dipolar field (the \"Left-ish\" pattern we simulated).\n#     *   **Comp 1+**: Often look \"speckled\" or messy, indicating they capture noise.\n#\n# Note: Since the data is synthetic, the sensor locations are idealized.\nplot_spatial_patterns(dss_evoked, n_components=3, show=False)\n\n# 4. Component Summary\n# --------------------\n# A dashboard for detailed inspection of Comp 0.\nplot_component_summary(dss_evoked, data=epochs, n_components=[0], show=False)\n\n# 5. Denoising Comparison\n# -----------------------\n# We reconstruct the data using ONLY the first component (the \"Signal\").\n# This removes the 50Hz interference and white noise.\nprint(\"Reconstructing data from first component...\")\nsources = dss_evoked.transform(epochs)\n# To reconstruct using only specific components, we zero out the others\nsources[1:, :, :] = 0\nepochs_denoised = dss_evoked.inverse_transform(sources)\nepochs_denoised = mne.EpochsArray(epochs_denoised, info)\n\n# Plot Original vs Denoised Evoked Response\n# *   **Expectation**: The \"Denoised\" trace should have smaller confidence intervals (shaded area)\n#     because the variable noise has been removed.\nplot_evoked_comparison(epochs, epochs_denoised, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Synthetic B: Bandpass Bias\nGoal: Isolate the **Oscillatory (50Hz)** component.\nNote: This component cancels out in the trial average! But DSS can find it by maximizing 50Hz power.\nBias: Maximize power in 48-52 Hz band.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Synthetic: Bandpass Bias (50Hz) ---\")\nbias_bp = BandpassBias(freq_band=(48, 52), sfreq=sfreq)\ndss_osc = DSS(n_components=5, bias=bias_bp)\n# For Bandpass, we often treat data as continuous (Raw), but Epochs work too (concatenated).\ndss_osc.fit(epochs)\n\n# Visualize\n# 1. Score Curve\nplot_score_curve(dss_osc, mode=\"ratio\", show=False)\n\n# 2. Component Time Series\n# *   **Expectation**: Comp 0 should look like a bursty/clean 50Hz oscillation.\n# *   **Note**: Unlike Evoked, these are not phase-locked, so peaks don't align across trials.\nplot_component_time_series(dss_osc, data=epochs, n_components=3, show=False)\n\n# 3. Spatial Patterns\n# *   **Expectation**: Comp 0 should show the \"Right-ish\" field pattern.\n# *   **Note**: This topography is distinct from the Evoked signal, showing how DSS separates sources spatially.\nplot_spatial_patterns(dss_osc, n_components=3, show=False)\n\n# 4. Component Summary\n# *   **Expectation**: PSD should show a very sharp peak at 50 Hz.\nplot_component_summary(dss_osc, data=epochs, n_components=[0], show=False)\n\n# 5. Denoising Comparison\n# -----------------------\n# Reconstruct data using the oscillator component.\nprint(\"Reconstructing data from oscillatory component...\")\n# We concatenate epochs for continuous reconstruction if desired, or keep as epochs\n# Here we keep as epochs to use plot_psd_comparison\nsources = dss_osc.transform(epochs)\nsources[1:, :, :] = 0\nepochs_osc = dss_osc.inverse_transform(sources)\nepochs_osc = mne.EpochsArray(epochs_osc, info)\n\n# Plot PSD Comparison\n# *   **Expectation**: The \"Denoised\" signal should have a massive peak at 50Hz\n#     and very little power elsewhere (noise suppressed).\nplot_psd_comparison(epochs, epochs_osc, show=True, fmax=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Real Data (MNE Sample)\nWe load real MEG data and perform the same two tasks:\n1.  **Trial Average Bias**: Recover auditory evoked response (M100).\n2.  **Bandpass Bias**: Recover Alpha rhythm (8-12 Hz) from background.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nLoading MNE Sample data...\")\n# Ensure MNE_DATA directory exists\nhome = os.path.expanduser(\"~\")\nmne_data_path = os.path.join(home, \"mne_data\")\nif not os.path.exists(mne_data_path):\n    with contextlib.suppress(OSError):\n        os.makedirs(mne_data_path)\n\ndata_path = sample.data_path()\nraw_fname = data_path / \"MEG\" / \"sample\" / \"sample_audvis_raw.fif\"\nevent_fname = data_path / \"MEG\" / \"sample\" / \"sample_audvis_raw-eve.fif\"\n\nraw = mne.io.read_raw_fif(raw_fname, preload=True, verbose=False)\nraw.pick_types(meg=\"grad\", eeg=False, eog=False, stim=False).crop(0, 60)\nprint(f\"Data: {len(raw.ch_names)} Gradiometers, 60s duration\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real A: Bandpass Bias (Alpha Rhythm)\nGoal: Find Alpha (8-12 Hz) components.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Real: Bandpass Bias (Alpha) ---\")\nbias_alpha = BandpassBias(freq_band=(8, 12), sfreq=raw.info[\"sfreq\"])\ndss_alpha = DSS(n_components=5, bias=bias_alpha)\ndss_alpha.fit(raw)\n\n# Visualize\n# 1. Score Curve\nplot_score_curve(dss_alpha, mode=\"ratio\", show=False)\n\n# 2. Component Time Series\n# *   **Expectation**: Strong rhythmic activity (alpha waves) in the first component.\nplot_component_time_series(dss_alpha, data=raw, n_components=5, show=False)\n\n# 3. Spatial Patterns\n# *   **Expectation**: Comp 0 shows a posterior/occipital topography (visual/alpha areas).\n# *   **Note**: The dots here represent the MEG sensors (gradiometers).\nplot_spatial_patterns(dss_alpha, n_components=5, show=False)\n\n# 4. Component Summary\n# *   **Expectation**: PSD peak in 8-12 Hz range.\nplot_component_summary(dss_alpha, data=raw, n_components=[0], show=False)\n\n# 5. Denoising Comparison\nprint(\"Reconstructing Alpha component...\")\nsources_alpha = dss_alpha.transform(raw)\nsources_alpha[1:, :] = 0\nraw_alpha = dss_alpha.inverse_transform(sources_alpha)\nraw_alpha = mne.io.RawArray(raw_alpha, raw.info)\n\n# Compare PSDs\n# *   **Expectation**: Denoised signal roughly follows original in alpha band but has lower noise floor.\nplot_psd_comparison(raw, raw_alpha, fmax=40, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real B: Trial Average Bias (Auditory Evoked)\nGoal: Find the M100 auditory response.\nWe first need to epoch the data around auditory events.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Real: Trial Average Bias (M100) ---\")\nevents = mne.read_events(event_fname)\n# Event ID 1 = Auditory/Left\nepochs_real = mne.Epochs(\n    raw,\n    events,\n    event_id=1,\n    tmin=-0.1,\n    tmax=0.4,\n    baseline=(None, 0),\n    preload=True,\n    verbose=False,\n)\nprint(f\"Epochs extracted: {len(epochs_real)}\")\n\ndss_m100 = DSS(n_components=5, bias=AverageBias())\ndss_m100.fit(epochs_real)\n\n# Visualize\n# 1. Score Curve\nplot_score_curve(dss_m100, mode=\"ratio\", show=False)\n\n# 2. Component Time Series\n# *   **Expectation**: Comp 0 should show a clear evoked potential (M100) that is\n#     visible even in the stacked single trials (if SNR is good enough) or at least in the mean.\nplot_component_time_series(dss_m100, data=epochs_real, n_components=5, show=False)\n\n# 3. Spatial Patterns\n# *   **Expectation**: Dipolar pattern over auditory cortex (temporal lobes).\n# *   **Observation**: You might see symmetric dipoles over left and right temporal areas.\nplot_spatial_patterns(dss_m100, n_components=5, show=False)\n\n# 4. Summary\nplot_component_summary(dss_m100, data=epochs_real, n_components=[0], show=False)\n\n# 5. Denoising Comparison\nprint(\"Reconstructing M100 component...\")\nsources = dss_m100.transform(epochs_real)\nsources[1:, :, :] = 0\nepochs_m100 = dss_m100.inverse_transform(sources)\nepochs_m100 = mne.EpochsArray(epochs_m100, epochs_real.info)\n\n# Compare Evoked Responses\n# *   **Expectation**: Cleaner M100 peak with reduced baseline noise.\nplot_evoked_comparison(epochs_real, epochs_m100, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\nWe successfully demonstrated the flexibility of DSS:\n*   **AverageBias**: Found phase-locked signals (Sine wave, M100) by averaging.\n*   **BandpassBias**: Found induced/oscillatory signals (50Hz, Alpha) by filtering.\n\nThe same algorithm, `DSS`, solved both problems simply by changing the definition of \"interesting\".\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}