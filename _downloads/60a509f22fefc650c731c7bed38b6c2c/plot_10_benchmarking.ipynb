{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 10. Efficiency Benchmark: DSS vs PCA, ICA, and Averaging.\n\nThis example demonstrates the superior efficiency\nof DSS in recovering evoked responses compared to standard methods.\n\nWe compare:\n1.  **Best Single Channel**: The channel with the highest signal-to-noise ratio.\n2.  **Channel Averaging**: Averaging the best 20 channels.\n3.  **PCA**: The Principal Component with the highest evoked power.\n4.  **FastICA**: The Independent Component with the highest evoked power.\n5.  **DSS**: The first component extracted using `AverageBias`.\n\n**Metric**:\nWe define \"SNR Proxy\" as the variance of the trial-averaged signal.\nSince the noise is uncorrelated across trials, averaging suppresses noise by $1/N_{trials}$.\nHigher variance of the average indicates better recovery of the phase-locked evoked response.\n\nAuthors: Sina Esmaeili (sina.esmaeili@umontreal.ca)\n         Hamza Abdelhedi (hamza.abdelhedi@umontreal.ca)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport mne\nimport numpy as np\nfrom sklearn.decomposition import PCA, FastICA\n\nfrom mne_denoise.dss import DSS, AverageBias\n\nprint(__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generate Synthetic Evoked Response Data\nWe simulate a dataset with a known \"Evoked\" source (M100-like waveform)\nembedded in spatially correlated noise.\n\n- Channels: 60\n- Time points: 350\n- Epochs: 100\n- Signal Power: 5.0\n- Noise Power: 3.0\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_epochs = 100\nn_channels = 60\nn_times = 350\nsfreq = 500\ntimes = np.linspace(-0.2, 0.5, n_times)\n\n# create M100-like waveform (Gabor patch)\nevoked_src = np.exp(-((times - 0.1) ** 2) / (2 * 0.03**2)) * np.sin(\n    2 * np.pi * 10 * times\n)\nevoked_src /= np.std(evoked_src)\n\n# Spatial pattern (e.g., bilateral dipoles)\nrng = np.random.default_rng(42)\npattern = np.sin(np.linspace(0, 2 * np.pi, n_channels))\npattern /= np.linalg.norm(pattern)\n\n# Generate Data\ndata = np.zeros((n_epochs, n_channels, n_times))\nsignal_power = 5.0\nnoise_power = 3.0\n\nprint(\"Generating synthetic data...\")\nfor i in range(n_epochs):\n    # Fixed signal (Evoked)\n    sig = signal_power * np.outer(pattern, evoked_src)\n\n    # Random noise (uncorrelated across trials, but some spatial structure)\n    # We mix random noise to create spatial correlation\n    noise_raw = rng.standard_normal((n_channels + 10, n_times))\n    mix_noise = rng.standard_normal((n_channels, n_channels + 10))\n    noise = noise_power * (mix_noise @ noise_raw)\n    noise /= np.std(noise)\n\n    data[i] = sig + noise\n\n# Create MNE Epochs for convenience\ninfo = mne.create_info(n_channels, sfreq, \"eeg\")\nepochs = mne.EpochsArray(data, info, tmin=-0.2, verbose=False)\n\n# Compute true Evoked for reference\ntrue_evoked_data = signal_power * evoked_src\n\nprint(f\"Data shape: {epochs.get_data().shape} (Epochs, Channels, Times)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper: Compute SNR Proxy\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_snr_proxy(data_3d):\n    \"\"\"\n    Compute SNR proxy: Variance of the trial-averaged signal.\n\n    Parameters\n    ----------\n    data_3d : ndarray (n_epochs, n_ch/n_comp, n_times)\n\n    Returns\n    -------\n    snr : float (for best channel/component)\n    best_idx : int\n    avg_waveform : ndarray (n_times,)\n    \"\"\"\n    # Average over epochs (Evoked response)\n    evoked = data_3d.mean(axis=0)\n\n    # Calculate variance (power) of the evoked response for each channel/component\n    power = np.var(evoked, axis=1)\n\n    best_idx = np.argmax(power)\n    best_snr = power[best_idx]\n    best_waveform = evoked[best_idx]\n\n    return best_idx, best_snr, best_waveform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 1: Best Single Channel\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nRunning Method 1: Best Single Channel...\")\nbest_ch_idx, snr_best_ch, wave_best_ch = compute_snr_proxy(epochs.get_data())\nprint(f\"  Best Channel: #{best_ch_idx}, SNR: {snr_best_ch:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 2: Averaging Best 20 Channels\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nRunning Method 2: Average of Best 20 Channels...\")\n# Rank channels by evoked power\nevoked_power = np.var(epochs.get_data().mean(axis=0), axis=1)\nbest_20_indices = np.argsort(evoked_power)[-20:]\n\n# Extract data for these 20 channels\ndata_20 = epochs.get_data()[:, best_20_indices, :]\n\n# Align signs to avoid cancellation!\n# We align to the single best channel (which is one of them)\nbest_ch_idx_local = np.argmax(evoked_power[best_20_indices])\nref_wave = data_20[:, best_ch_idx_local, :].mean(axis=0)\n\naligned_data_20 = data_20.copy()\nfor i in range(20):\n    # Check correlation with reference\n    ch_wave = data_20[:, i, :].mean(axis=0)\n    if np.corrcoef(ch_wave, ref_wave)[0, 1] < 0:\n        aligned_data_20[:, i, :] *= -1\n\n# Average spatially (across channels) -> (n_epochs, 1, n_times)\n# effectively creating a \"virtual channel\"\ndata_avg_20 = aligned_data_20.mean(axis=1, keepdims=True)\n\n_, snr_avg_20, wave_avg_20 = compute_snr_proxy(data_avg_20)\nprint(f\"  Average 20 SNR: {snr_avg_20:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 3: PCA (sklearn)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nRunning Method 3: PCA...\")\n# Reshape to (n_samples_total, n_channels) for sklearn\n# PCA finds directions of maximum TOTAL variance (Signal + Noise)\nX_concat = np.transpose(epochs.get_data(), (0, 2, 1)).reshape(\n    -1, n_channels\n)  # (n_epochs*n_times, n_ch)\n\npca = PCA(n_components=10, random_state=42)\nX_pca = pca.fit_transform(X_concat)\n\n# Reshape back to (n_epochs, n_times, n_comps) -> (n_epochs, n_comps, n_times)\ndata_pca = X_pca.reshape(n_epochs, n_times, 10).transpose(0, 2, 1)\n\nbest_pc_idx, snr_pca, wave_pca = compute_snr_proxy(data_pca)\nprint(f\"  Best PC: #{best_pc_idx}, SNR: {snr_pca:.2f}\")\n# Fix sign if anti-correlated\nif np.corrcoef(wave_pca, true_evoked_data)[0, 1] < 0:\n    wave_pca *= -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 4: FastICA (sklearn)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nRunning Method 4: FastICA...\")\n# ICA tries to find independent components (non-Gaussian)\n# Often effective for artifacts, effectively random for Gaussians\nica = FastICA(n_components=10, random_state=42)\nX_ica = ica.fit_transform(X_concat)\n\ndata_ica = X_ica.reshape(n_epochs, n_times, 10).transpose(0, 2, 1)\n\nbest_ic_idx, snr_ica, wave_ica = compute_snr_proxy(data_ica)\nprint(f\"  Best IC: #{best_ic_idx}, SNR: {snr_ica:.2f}\")\n\n# Re-scale ICA (since ICA has arbitrary scale) to match best channel magnitude for fair visual comparison\nscaling = np.std(wave_best_ch) / np.std(wave_ica)\nwave_ica *= scaling\nif np.corrcoef(wave_ica, true_evoked_data)[0, 1] < 0:\n    wave_ica *= -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 5: DSS (Trial Averaging)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nRunning Method 5: DSS (Our Method)...\")\n# We use AverageBias (default axis='epochs'), which specifically optimizes for the evoked response\n# (maximizing ratio of Mean / Variance).\n\ndss = DSS(bias=AverageBias(), n_components=5)\ndss.fit(epochs)\ndata_dss = dss.transform(epochs)  # returns (n_epochs, n_comps, n_times)\n\n# Component 0 is guaranteed to be the best by DSS design (eigenvalue sorting)\nbest_dss_idx = 0\n_, snr_dss, wave_dss = compute_snr_proxy(data_dss)\n# But let's pick strictly by our proxy just in case\nbest_dss_idx, snr_dss, wave_dss = compute_snr_proxy(data_dss)\nprint(f\"  Best DSS: #{best_dss_idx}, SNR: {snr_dss:.2f}\")\n\n# Re-scale DSS pattern if sign flipped (arbitrary sign)\nif np.corrcoef(wave_dss, true_evoked_data)[0, 1] < 0:\n    wave_dss *= -1\n\n# Scale for visual comparison (DSS is scale-invariant/whitened)\nwave_dss *= np.std(wave_best_ch) / np.std(wave_dss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Visualization: Bar Chart Comparison\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "methods = [\"Best Channel\", \"Avg 20 Ch\", \"Best PCA\", \"Best ICA\", \"DSS\"]\nsnrs = [\n    snr_best_ch,\n    snr_avg_20,\n    snr_pca,\n    snr_ica,\n    snr_dss,\n]  # Raw variance values might vary due to scale\n# We normalize improvements relative to Best Channel = 1.0\nrelative_improvement = np.array(snrs) / snrs[0]\n\n\n# IMPORTANT: ICA/PCA/DSS scales are arbitrary.\n# Comparing \"Raw Variance\" (which is SNR Proxy *if* noise is constant) is tricky across methods\n# if they apply different gains.\n# However, \"SNR\" in the context of Evoked BCI is usually (Power of Avg) / (Residual Variance).\n# Our proxy `var(mean)` assumes noise cancels out exactly or similarly.\n# A more robust SNR is (Power of Signal) / (Power of Noise).\n#\n# Let's compute a \"Real SNR\" metric for the plot:\n# SNR = Var(Evoked) / Var(Residual)\ndef compute_true_snr(data_3d, idx):\n    evoked = data_3d.mean(axis=0)[idx]\n    residual = data_3d[:, idx, :] - evoked[None, :]\n    return np.var(evoked) / np.var(residual)\n\n\nprint(\"\\nCalculating True SNR (Signal / Residual)...\")\ntrue_snr_vals = []\ntrue_snr_vals.append(compute_true_snr(epochs.get_data(), best_ch_idx))\ntrue_snr_vals.append(compute_true_snr(data_avg_20, 0))\ntrue_snr_vals.append(compute_true_snr(data_pca, best_pc_idx))\ntrue_snr_vals.append(compute_true_snr(data_ica, best_ic_idx))\ntrue_snr_vals.append(compute_true_snr(data_dss, best_dss_idx))\n\nrelative_improvement_true = np.array(true_snr_vals) / true_snr_vals[0]\n\nfig, ax = plt.subplots(figsize=(10, 6))\nbars = ax.bar(\n    methods,\n    relative_improvement_true,\n    color=[\"gray\", \"gray\", \"orange\", \"purple\", \"blue\"],\n    alpha=0.8,\n    edgecolor=\"k\",\n)\n\n# Highlight DSS\nbars[-1].set_alpha(1.0)\nbars[-1].set_linewidth(2)\n\n# Add labels\nfor bar, val in zip(bars, relative_improvement_true):\n    height = bar.get_height()\n    ax.text(\n        bar.get_x() + bar.get_width() / 2.0,\n        height + 0.1,\n        f\"{val:.1f}x\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontweight=\"bold\",\n        fontsize=12,\n    )\n\nax.axhline(1.0, color=\"r\", linestyle=\"--\", alpha=0.5, label=\"Baseline\")\nax.set_ylabel(\"SNR Improvement (Relative to Best Channel)\")\nax.set_title(\"Denoising Efficiency Comparison (Higher is Better)\")\nax.legend()\nplt.tight_layout()\nplt.show(block=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization: Time Course Comparison\nOverlay the recovered waveforms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n\nt = times\nax.plot(\n    t,\n    wave_best_ch / np.max(np.abs(wave_best_ch)),\n    \"k--\",\n    alpha=0.4,\n    label=\"Best Single Channel\",\n)\nax.plot(\n    t,\n    wave_avg_20 / np.max(np.abs(wave_avg_20)),\n    \"g-.\",\n    alpha=0.6,\n    label=\"Avg 20 Channels\",\n)\nax.plot(\n    t, wave_pca / np.max(np.abs(wave_pca)), color=\"orange\", alpha=0.6, label=\"Best PCA\"\n)\n# ax.plot(t, wave_ica, color='purple', alpha=0.6, label='Best ICA') # ICA often poor for this\nax.plot(\n    t, wave_dss / np.max(np.abs(wave_dss)), \"b\", linewidth=2.5, label=\"DSS (Optimal)\"\n)\n\n# Plot ground truth\nax.plot(\n    t,\n    evoked_src / np.max(np.abs(evoked_src)),\n    \"r:\",\n    linewidth=2,\n    alpha=0.8,\n    label=\"True Source\",\n)\n\nax.set_xlabel(\"Time (s)\")\nax.set_ylabel(\"Normalized Amplitude\")\nax.set_title(\"Recovered Evoked Responses\")\nax.legend(loc=\"upper right\")\nax.grid(True, linestyle=\":\")\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nExample 10 Complete! DSS should show the highest SNR improvement.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}