{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 08. Blind Source Separation & ICA Equivalence.\n\nThis example demonstrates how **Nonlinear DSS** can perform Blind Source Separation (BSS),\neffectively recovering independent sources from mixed signals. It explicitly shows\nthe equivalence between DSS with specific nonlinearities and Independent Component Analysis (ICA).\n\nWe cover:\n1.  **Synthetic BSS**: Separating mixed Super-Gaussian sources (speech/bursts) and Sub-Gaussian sources.\n2.  **ICA Equivalence**: Comparing DSS (`TanhMaskDenoiser`, `KurtosisDenoiser`) against `sklearn.decomposition.FastICA`.\n3.  **Real MEG Data**: Performing blind decomposition of the MNE Sample dataset to find artifacts (EOG/ECG) and brain sources.\n\nAuthors: Sina Esmaeili (sina.esmaeili@umontreal.ca)\n         Hamza Abdelhedi (hamza.abdelhedi@umontreal.ca)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport mne\nimport numpy as np\nfrom mne.datasets import sample\nfrom scipy import stats\n\nfrom mne_denoise.dss import IterativeDSS, KurtosisDenoiser, TanhMaskDenoiser, beta_tanh\nfrom mne_denoise.viz import (\n    plot_component_summary,\n    plot_component_time_series,\n    plot_overlay_comparison,\n)\n\nprint(__doc__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Synthetic Blind Source Separation\nWe generate synthetic sources with different statistical properties (Super-Gaussian, Sub-Gaussian)\nand mix them linearly. We then attempt to recover them using DSS and FastICA.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- 1. Creating Synthetic Mixed Data ---\")\n\nn_samples = 2000\ntime = np.linspace(0, 8, n_samples)\n\n# 1. Super-Gaussian (Laplace) - \"Sparse\" / \"Bursty\"\ns1 = stats.laplace.rvs(size=n_samples)\ns1 /= s1.std()\n\n# 2. Super-Gaussian (Square Wave) - High Kurtosis\ns2 = np.sign(np.sin(3 * time))\ns2 /= s2.std()\n\n# 3. Sub-Gaussian (Sinusoid) - Low Kurtosis\ns3 = np.sin(10 * time)\ns3 /= s3.std()\n\n# 4. Gaussian Noise\ns4 = np.random.randn(n_samples)\n\n# Stack true sources\nS_true = np.c_[s1, s2, s3, s4].T\nn_sources = S_true.shape[0]\n\n# Mix sources\nnp.random.seed(42)\nA = np.random.randn(n_sources, n_sources)  # Mixing matrix\nX = np.dot(A, S_true)  # Mixed signals\n\n# Visualize\nfig, axes = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\naxes[0].plot(time, S_true.T + np.arange(n_sources) * 5)\naxes[0].set_title(\"True Sources\")\naxes[0].set_yticks(np.arange(n_sources) * 5)\naxes[0].set_yticklabels([f\"S{i}\" for i in range(n_sources)])\n\naxes[1].plot(time, X.T + np.arange(n_sources) * 5)\naxes[1].set_title(\"Mixed Signals (Input)\")\naxes[1].set_yticks(np.arange(n_sources) * 5)\n\nplt.tight_layout()\nplt.show(block=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run DSS with Tanh Nonlinearity (Robust ICA)\nThe `TanhMaskDenoiser` implements the `tanh` nonlinearity, which is robust to outliers.\n\n**Convergence Comparison**:\nWe demonstrate the speedup of the \"Newton step\" (`beta=beta_tanh`) vs standard gradient ascent (`beta=None`).\nThe Newton step is what makes FastICA fast (quadratic convergence).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nRunning DSS with Tanh Nonlinearity (Robust)...\")\n\n# 1. Gradient Ascent (Slow)\nprint(\"  Fitting with Gradient Ascent (beta=None)...\")\ndss_grad = IterativeDSS(\n    denoiser=TanhMaskDenoiser(),\n    method=\"deflation\",\n    n_components=n_sources,\n    beta=None,  # Gradient ascent\n    random_state=42,\n    verbose=False,\n)\ndss_grad.fit(X)\n\n# 2. Newton Method (Fast - FastICA style)\nprint(\"  Fitting with Newton Method (beta=beta_tanh)...\")\ndss_tanh = IterativeDSS(\n    denoiser=TanhMaskDenoiser(),\n    method=\"deflation\",\n    n_components=n_sources,\n    beta=beta_tanh,  # Newton step\n    random_state=42,\n    verbose=False,\n)\ndss_tanh.fit(X)\nS_dss_tanh = dss_tanh.transform(X)\n\n# Compare iterations\niters_grad = dss_grad.convergence_info_[:, 0].sum()\niters_newton = dss_tanh.convergence_info_[:, 0].sum()\nprint(f\"  Gradient Iterations: {iters_grad:.0f}\")\nprint(\n    f\"  Newton Iterations:   {iters_newton:.0f} (Speedup: {iters_grad / iters_newton:.1f}x)\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run DSS with Kurtosis Nonlinearity (Standard FastICA)\n`KurtosisDenoiser` with `nonlinearity='cube'` maximizes kurtosis ($s^3$), which is\nthe classic definition of FastICA.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Running DSS with Kurtosis Nonlinearity (FastICA standard)...\")\ndss_kurt = IterativeDSS(\n    denoiser=KurtosisDenoiser(nonlinearity=\"cube\"),\n    method=\"deflation\",\n    n_components=n_sources,\n    beta=-3.0,  # Newton step for kurtosis\n    random_state=42,\n    verbose=False,\n)\ndss_kurt.fit(X)\nS_dss_kurt = dss_kurt.transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison with sklearn FastICA\nWe run `sklearn.decomposition.FastICA` to serve as a ground truth benchmark.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import FastICA\n\nprint(\"Running sklearn FastICA (Benchmark)...\")\nica = FastICA(\n    n_components=n_sources, algorithm=\"deflation\", fun=\"logcosh\", random_state=42\n)\nS_fastica = ica.fit_transform(X.T).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Performance (Correlation with True Sources)\nWe compute the absolute correlation matrix between recovered components and true sources.\nA perfect recovery would have one 1.0 per row/column (permutation matrix).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def match_sources(S_est, S_true):\n    \"\"\"Calculate best correlation match for each source.\"\"\"\n    n_est = S_est.shape[0]\n    n_true = S_true.shape[0]\n    corr = np.zeros((n_est, n_true))\n    for i in range(n_est):\n        for j in range(n_true):\n            corr[i, j] = np.abs(np.corrcoef(S_est[i], S_true[j])[0, 1])\n    return corr\n\n\nprint(\"\\n--- Evaluation ---\")\n\ncorr_tanh = match_sources(S_dss_tanh, S_true)\ncorr_kurt = match_sources(S_dss_kurt, S_true)\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\nim0 = axes[0].imshow(corr_tanh, vmin=0, vmax=1, cmap=\"Greens\")\naxes[0].set_title(\n    f\"DSS (Tanh) Match\\nMean Max Corr: {np.mean(np.max(corr_tanh, axis=1)):.3f}\"\n)\naxes[0].set_ylabel(\"Recovered\")\naxes[0].set_xlabel(\"True\")\nplt.colorbar(im0, ax=axes[0])\n\nim1 = axes[1].imshow(corr_kurt, vmin=0, vmax=1, cmap=\"Blues\")\naxes[1].set_title(\n    f\"DSS (Kurtosis) Match\\nMean Max Corr: {np.mean(np.max(corr_kurt, axis=1)):.3f}\"\n)\naxes[1].set_xlabel(\"True\")\nplt.colorbar(im1, ax=axes[1])\n\ncorr_ica = match_sources(S_fastica, S_true)\nim2 = axes[2].imshow(corr_ica, vmin=0, vmax=1, cmap=\"Oranges\")\naxes[2].set_title(\n    f\"sklearn FastICA Match\\nMean Max Corr: {np.mean(np.max(corr_ica, axis=1)):.3f}\"\n)\naxes[2].set_xlabel(\"True\")\nplt.colorbar(im2, ax=axes[2])\n\nplt.suptitle(\"Source Recovery Quality (Abs Correlation)\")\nplt.tight_layout()\nplt.show(block=False)\n\n# Plot recovered time series using viz module\nprint(\"Visualizing Recovered Sources (Stacked)...\")\n# We treat the sources as \"components\" of the estimator\nplot_component_time_series(dss_tanh, data=X, show=False)\nplt.gcf().suptitle(\"Recovered Sources (DSS Tanh) - Newton Optimization\")\nplt.show(block=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Blind Separation of Real MEG Data\nWe apply nonlinear DSS to the MNE sample dataset (MEG channels) to blindly extract\nartifacts (EOG, ECG) and brain sources. This is similar to running `mne.preprocessing.ICA`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- 2. Real MEG Data (Blind Separation) ---\")\n\ndata_path = sample.data_path()\nraw_fname = data_path / \"MEG\" / \"sample\" / \"sample_audvis_raw.fif\"\nraw = mne.io.read_raw_fif(\n    raw_fname, verbose=False\n)  # list_url=[] prevents download print spam usually\nraw.crop(0, 60).pick_types(meg=True, eeg=False, eog=True, stim=False).load_data()\n\n# Filter to remove drifts and high freq noise\nraw.filter(1, 40, verbose=False)\n\n# Prepare MEG-only data for BSS\n# We want to find artifacts *in the MEG channels*, ensuring we don't just pick up the EOG channel itself.\nraw_meg = raw.copy().pick_types(meg=True, eeg=False, eog=False, stim=False)\nprint(f\"Data shape (MEG only): {raw_meg.get_data().shape}\")\n\n# Fit DSS-Tanh (Blind Decomposition)\nprint(\"Fitting Blind DSS (this may take a moment)...\")\n\nn_components = 15\ndss_meg = IterativeDSS(\n    denoiser=TanhMaskDenoiser(),\n    method=\"deflation\",\n    n_components=n_components,\n    beta=beta_tanh,\n    verbose=True,\n)\ndss_meg.fit(raw_meg)\n\n# Identify Artifacts by correlation with EOG channel\n# We use the separate EOG channel to validate which extracted source corresponds to blinks.\neog_ch = raw.get_data(picks=\"eog\")[0]\nsources = dss_meg.transform(raw_meg)\n\ncorrs = [np.abs(np.corrcoef(s, eog_ch)[0, 1]) for s in sources]\nblink_idx = np.argmax(corrs)\nprint(f\"\\nMost likely EOG component: #{blink_idx} (Corr: {corrs[blink_idx]:.3f})\")\n\n# Visualize the Blink Component\nprint(\"Visualizing Blink Component...\")\nplot_component_summary(dss_meg, data=raw_meg, n_components=[blink_idx], show=False)\nplt.gcf().suptitle(f\"Component #{blink_idx}: Blindly Extracted EOG Artifact\")\nplt.show(block=False)\n\n# Visualize a Brain Component (candidate)\n# We look for a component that is NOT the blink argmax\ncandidate_indices = [i for i in range(n_components) if i != blink_idx]\nbrain_idx = candidate_indices[1]  # Pick arbitrary one, e.g. 2nd candidate\nprint(f\"Visualizing Candidate Brain Component #{brain_idx}...\")\n\nplot_component_summary(dss_meg, data=raw_meg, n_components=[brain_idx], show=False)\nplt.gcf().suptitle(f\"Component #{brain_idx}: Candidate Brain Source\")\nplt.show(block=False)\n\n# Overlay comparison for EOG\n# Show how the extracted component matches the EOG channel\neog_raw = mne.io.RawArray(\n    eog_ch[None, :], mne.create_info([\"EOG\"], raw.info[\"sfreq\"], \"eog\")\n)\ncomp_raw = mne.io.RawArray(\n    sources[blink_idx : blink_idx + 1], mne.create_info(1, raw.info[\"sfreq\"], \"misc\")\n)\n\nplot_overlay_comparison(\n    eog_raw,\n    comp_raw,\n    start=10,\n    stop=20,\n    title=\"EOG Channel vs Extracted Component (Time Domain)\",\n    show=False,\n)\nplt.show(block=False)\n\nprint(\"\\nBlind Source Separation complete!\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}