{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Denoising Evoked Responses.\n\nThis example demonstrates how to use DSS to enhance **Evoked Responses** (ERPs/ERFs).\nWe explore two strategies:\n1.  **Standard Denoising**: Using `AverageBias` to enhance the common evoked response (N100/P200).\n2.  **Contrast Enhancement**: Building a **Custom Bias** to isolate the *difference* between two experimental conditions (Left vs Right Audio).\n\nAuthors: Sina Esmaeili (sina.esmaeili@umontreal.ca)\n         Hamza Abdelhedi (hamza.abdelhedi@umontreal.ca)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import contextlib\nimport os\n\nimport matplotlib.pyplot as plt\nimport mne\nimport numpy as np\nfrom mne.datasets import sample\n\nfrom mne_denoise.dss import DSS, AverageBias, LinearDenoiser\nfrom mne_denoise.viz import (\n    plot_component_summary,\n    plot_component_time_series,\n    plot_evoked_comparison,\n    plot_score_curve,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 0: Synthetic Data Demo\nBefore using real data, let's demonstrate the concept on a simple simulation.\nWe create a known \"Evoked Response\" (damped sinusoid) and bury it in noise.\n\n**Goal**: Recover the template signal from the noisy mixture.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Part 0: Synthetic Data Demo ---\")\n\n# 1. Simulate Data\nrng = np.random.default_rng(42)\nn_epochs = 50\nn_channels = 10\nn_times = 200\nsfreq = 100\ntimes = np.arange(n_times) / sfreq\n\n# Define the \"True\" Evoked Response (N100-like)\n# Peak around 100ms (0.1s)\nsignal = -np.exp(-((times - 0.5) ** 2) / 0.01) * np.sin(2 * np.pi * 5 * times)\nsignal /= np.max(np.abs(signal))  # Normalize\n\n# Embed in Epochs\nepochs_data = np.zeros((n_epochs, n_channels, n_times))\nmixing = rng.standard_normal(n_channels)\nmixing /= np.linalg.norm(mixing)\nsignal_strength = 0.5\n\nfor i in range(n_epochs):\n    # Noise: non-phase-locked (random every trial)\n    noise = rng.standard_normal((n_channels, n_times)) * 2.0\n    # Add signal (phase-locked)\n    for ch in range(n_channels):\n        epochs_data[i, ch, :] = noise[ch] + mixing[ch] * signal * signal_strength\n\n# Create MNE Epochs\ninfo_sim = mne.create_info(n_channels, sfreq, \"eeg\")\nevents_sim = np.array([[i * 1000, 0, 1] for i in range(n_epochs)])\nepochs_sim = mne.EpochsArray(\n    epochs_data, info_sim, events=events_sim, tmin=-0.5, verbose=False\n)\n\n# 2. Fit DSS\ndss_sim = DSS(n_components=5, bias=AverageBias(axis=\"epochs\"))\ndss_sim.fit(epochs_sim)\n\n# 3. Visualize Results\n# Plot true signal vs First DSS component\n# DSS component sign is arbitrary, so we match it to the template for comparison\nsources_sim = dss_sim.transform(epochs_sim)\nevoked_source = sources_sim.mean(axis=0)[0]  # First component, averaged trials\nif np.corrcoef(evoked_source, signal)[0, 1] < 0:\n    evoked_source *= -1\n\nplt.figure(figsize=(8, 4))\nplt.plot(times, signal, \"k--\", label=\"True Signal\", alpha=0.6)\nplt.plot(\n    times,\n    evoked_source / np.max(np.abs(evoked_source)),\n    \"r-\",\n    label=\"Recovered (DSS Comp 0)\",\n)\nplt.plot(\n    times,\n    epochs_sim.average().data[0] / np.max(np.abs(epochs_sim.average().data[0])),\n    \"g-\",\n    alpha=0.3,\n    label=\"Channel Average (Noisy)\",\n)\nplt.title(\"Synthetic Demo: Signal Recovery\")\nplt.legend()\nplt.show(block=False)\n\nprint(\"Synthetic demo complete. Proceeding to Real Data...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Loading MNE Sample data...\")\nhome = os.path.expanduser(\"~\")\nmne_data_path = os.path.join(home, \"mne_data\")\nif not os.path.exists(mne_data_path):\n    with contextlib.suppress(OSError):\n        os.makedirs(mne_data_path)\n\ndata_path = sample.data_path()\nraw_fname = data_path / \"MEG\" / \"sample\" / \"sample_audvis_raw.fif\"\nraw = mne.io.read_raw_fif(raw_fname, preload=True, verbose=False)\nraw.crop(0, 60)  # Keep it short for speed\n\n# Filter to clearer evoked band (1-40 Hz)\nraw.filter(1, 40, fir_design=\"firwin\")\n\n# Extract events\nevents = mne.find_events(raw, stim_channel=\"STI 014\")\nevent_id = {\"Auditory/Left\": 1, \"Auditory/Right\": 2}\n\n# Create Epochs\nepochs = mne.Epochs(\n    raw,\n    events,\n    event_id,\n    tmin=-0.2,\n    tmax=0.5,\n    baseline=(None, 0),\n    reject={\"grad\": 4000e-13, \"mag\": 4e-12, \"eog\": 150e-6},\n    preload=True,\n    verbose=False,\n)\n\n# Pick MEG data for DSS\nepochs_meg = epochs.copy().pick_types(meg=True, eeg=False, eog=False, exclude=\"bads\")\nprint(f\"Epochs: {len(epochs_meg)} trials, {len(epochs_meg.ch_names)} channels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Standard Evoked Denoising\n**Goal**: Maximize the ratio of (Evoked Power) / (Total Power).\nThis finds components that are perfectly repeatable across trials (the \"Evoked Response\").\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Part 1: Standard Trial Average Bias ---\")\n\n# 1. Fit DSS\n# We use AverageBias(axis='epochs'), which replaces every trial with the mean of all trials.\ndss_std = DSS(\n    n_components=10,\n    bias=AverageBias(axis=\"epochs\"),\n    cov_method=\"empirical\",\n    cov_kws={\"n_jobs\": 1},\n)\ndss_std.fit(epochs_meg)\n\n# Visualize\n# The score curve shows how \"evoked\" each component is (0 to 1).\nplot_score_curve(dss_std, mode=\"ratio\", show=False)\n\n# Time Series of top components\nplot_component_time_series(dss_std, data=epochs_meg, n_components=5, show=False)\n\n# The first component should be the dominant N100 response.\nplot_component_summary(dss_std, data=epochs_meg, n_components=[0], show=False)\n\n# 3. Denoising Effect\n# We reconstruct the data using ONLY the top few reproducible components.\n# This removes \"non-evoked\" background noise (alpha waves, etc. that are not phase-locked).\nkeep_n = 5\nprint(f\"Reconstructing Evoked with top {keep_n} components...\")\n\n# Transform -> Zero out noise -> Inverse\nsources = dss_std.transform(epochs_meg)\n# Create a mask to keep only top N\nmask = np.zeros(dss_std.n_components, dtype=bool)\nmask[:keep_n] = True\n\n# Inverse transform (filtering out the rest)\nclean_data = dss_std.inverse_transform(sources, component_indices=mask)\nepochs_clean = mne.EpochsArray(\n    clean_data,\n    epochs_meg.info,\n    tmin=epochs_meg.tmin,\n    events=epochs_meg.events,\n    event_id=epochs_meg.event_id,\n)\n\n# Compare Global Field Power\nplot_evoked_comparison(\n    epochs_meg,\n    epochs_clean,\n    labels=(\"Original\", f\"Denoised (Top {keep_n})\"),\n    show=False,\n)\nplt.show(block=False)  # Show it but don't stop execution\n\n\n# Quantify Improvement (SNR = Peak Evoked Power / Baseline Variance)\ndef get_snr(ep):\n    evoked = ep.average()\n    gfp = np.std(evoked.data, axis=0)  # spatial std (GFP)\n    # SNR = Peak post-stim / Mean pre-stim\n    return np.max(gfp[ep.times > 0]) / np.mean(gfp[ep.times < 0])\n\n\nsnr_in = get_snr(epochs_meg)\nsnr_out = get_snr(epochs_clean)\nprint(\n    f\"SNR Improvement: {snr_in:.2f} -> {snr_out:.2f} ({snr_out / snr_in:.1f}x improvement)\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Custom Contrast Bias (Oddball / Difference)\n**Goal**: Find components that maximize the **Difference** between Condition A and B.\nThis is useful for isolating the specific network responsible for distinguishing stimuli.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Part 2: Custom Contrast Bias ---\")\n\n\n# Define Custom Bias Class\nclass ContrastBias(LinearDenoiser):\n    \"\"\"Enhance the difference between two conditions.\"\"\"\n\n    def __init__(self, events, id_a, id_b):\n        self.events = events\n        self.id_a = id_a\n        self.id_b = id_b\n\n    def apply(self, data):\n        # data shape: (n_channels, n_times, n_epochs)\n        # Note: 'data' passed to apply is usually the full epoch data matrix\n        # We need to know which epoch belongs to which condition.\n        # Ideally, we pass 'events' to init so we can index.\n\n        # Identify indices\n        idx_a = [i for i, evt in enumerate(self.events) if evt[2] == self.id_a]\n        idx_b = [i for i, evt in enumerate(self.events) if evt[2] == self.id_b]\n\n        if len(idx_a) == 0 or len(idx_b) == 0:\n            raise ValueError(\"Events for Condition A or B not found in data.\")\n\n        # Compute means\n        # data is (n_ch, n_times, n_epochs)\n        mean_a = data[:, :, idx_a].mean(axis=2)\n        mean_b = data[:, :, idx_b].mean(axis=2)\n\n        # The 'Biased' signal is the Difference Wave\n        diff = mean_a - mean_b\n\n        # We start with a zero array\n        biased = np.zeros_like(data)\n\n        # For this bias, we want to maximize power in the difference.\n        # So we replace *every* trial with the difference wave.\n        # (Or we could replace A trials with +Diff/2 and B trials with -Diff/2,\n        #  but projecting onto the simple Difference vector is robust).\n        biased = np.broadcast_to(diff[:, :, np.newaxis], data.shape).copy()\n\n        return biased\n\n\n# 1. Setup Custom Bias\n# Left (1) vs Right (2)\ncustom_bias = ContrastBias(epochs_meg.events, id_a=1, id_b=2)\n\n# 2. Fit DSS\ndss_diff = DSS(\n    n_components=10, bias=custom_bias, cov_method=\"empirical\", cov_kws={\"n_jobs\": 1}\n)\ndss_diff.fit(epochs_meg)\n\n# 3. Visualize\n# Component 0 should be the \"Difference Component\".\nplot_score_curve(dss_diff, mode=\"ratio\", show=False)\n\n# Let's plot the time series of Comp 0 for Left vs Right conditions separate.\n# We expect to see a strong separation.\nsrc_diff = dss_diff.transform(epochs_meg)  # (n_epochs, n_comps, n_times)\n\n# Average by condition\nsrc_left = src_diff[epochs_meg.events[:, 2] == 1].mean(axis=0)\nsrc_right = src_diff[epochs_meg.events[:, 2] == 2].mean(axis=0)\n\ntimes = epochs_meg.times\nplt.figure(figsize=(10, 4))\nplt.plot(times, src_left[0], label=\"Left Audio\", color=\"tab:blue\")\nplt.plot(times, src_right[0], label=\"Right Audio\", color=\"tab:orange\")\nplt.title(\"DSS Contrast Component 0: Left vs Right\")\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Amplitude (AU)\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# 4. Topography of the Difference\n# This topography explains the *difference* between left and right.\nplot_component_summary(dss_diff, data=epochs_meg, n_components=[0], show=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}