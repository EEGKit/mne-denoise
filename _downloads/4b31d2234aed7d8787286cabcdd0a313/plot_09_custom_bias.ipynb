{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 09. Custom DSS: Defining Your Own Bias.\n\nThis example demonstrates how to extend DSS by defining **custom bias criteria**.\nThis is useful when you have domain-specific knowledge about the target source\n(e.g., \"it has sharp gradients\", \"it occurs after a specific trigger\", etc.).\n\nWe cover two ways to define custom biases:\n1.  **Subclassing `LinearDenoiser`**: For full control over the bias matrix computation.\n2.  **Using `function_bias`**: For simple weighting strategies based on auxiliary data.\n\nHere, we implement a **Gradient Trigger Bias** that finds sources with sharp\ntransients (high temporal gradient) by weighting time points where the gradient magnitude is high.\n\nAuthors: Sina Esmaeili (sina.esmaeili@umontreal.ca)\n         Hamza Abdelhedi (hamza.abdelhedi@umontreal.ca)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import signal\n\nfrom mne_denoise.dss import DSS, LinearDenoiser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Defining a Custom Bias Class\nTo define a custom linear bias, we subclass `mne_denoise.dss.LinearDenoiser`.\nWe must implement the `compute_bias(data)` method, which returns the\ncovariance matrix of the \"biased\" (filtered/weighted) data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class GradientTriggerBias(LinearDenoiser):\n    \"\"\"\n    Custom IDSS Bias that emphasizes signals with sharp gradients.\n\n    It weights the covariance matrix based on the magnitude of the\n    temporal gradient of the data.\n\n    Parameters\n    ----------\n    threshold : float\n        Percentile (0-100) of gradient magnitude to keep.\n        Only time points with gradient > percentile are used.\n    \"\"\"\n\n    def __init__(self, threshold_percentile=90):\n        self.threshold_percentile = threshold_percentile\n\n    def apply(self, data):\n        \"\"\"\n        Apply bias transformation to data.\n\n        Parameters\n        ----------\n        data : ndarray, shape (n_channels, n_times)\n            The input data (usually whitened).\n\n        Returns\n        -------\n        biased_data : ndarray, shape (n_channels, n_times)\n            The biased data (weighted by gradient).\n        \"\"\"\n        # 1. Compute temporal gradient (approximate derivative)\n        # diff(data, axis=1) gives (n_ch, n_times-1)\n        grad = np.diff(data, axis=1, prepend=data[:, :1])\n\n        # 2. Compute gradient magnitude (energy across channels) at each time point\n        # sum of squares across channels\n        grad_energy = np.sum(grad**2, axis=0)\n\n        # 3. Determine threshold\n        thresh = np.percentile(grad_energy, self.threshold_percentile)\n\n        # 4. Create a mask (float for multiplication)\n        # We keep time points where gradient energy is high\n        mask = (grad_energy > thresh).astype(float)\n\n        print(\n            f\"  GradientTriggerBias: Weighting {np.sum(mask)} / {len(mask)} samples ({mask.mean() * 100:.1f}%)\"\n        )\n\n        # 5. Return weighted data\n        # Covariance C_bias will later be computed as (biased_data @ biased_data.T) / N\n        return data * mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Generating Synthetic Data with Transients\nWe create a dataset with:\n- A \"Transient\" Source: Rare sharp spikes (gradient target).\n- A \"Background\" Source: Smooth oscillation (10 Hz).\n- Noise: Gaussian white noise.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples = 2000\ntime = np.arange(n_samples) / 200.0  # 200 Hz\n\n# Source 1: Sharp Transients (The Target)\ns1 = np.zeros(n_samples)\n# Add random spikes\nrng = np.random.default_rng(42)\nspike_indices = rng.choice(n_samples, 20, replace=False)\ns1[spike_indices] = 5.0  # Impulses\n# Convolve with a sharp kernel to make them \"transients\" but not single-sample\nkernel = signal.windows.exponential(20, tau=3.0)\ns1 = np.convolve(s1, kernel, mode=\"same\")\ns1 /= s1.std()\n\n# Source 2: Smooth Background (Distractor)\n# We make it slower (2 Hz) so its gradient is lower than the sharp transients\ns2 = np.sin(2 * np.pi * 2 * time)\ns2 /= s2.std()\n\n# Source 3: Removed (White noise has too high gradient!)\n# We only use Target and Distractor for clear demonstration\n# s3 = rng.standard_normal(n_samples)\n\nS = np.array([s1, s2])\nn_sources = S.shape[0]\n\n# Mixing\nA = rng.standard_normal((5, n_sources))\nX = A @ S\n# Add sensor noise\nX += 0.1 * rng.standard_normal(X.shape)\n\nprint(f\"Synthesized Data: {X.shape} (5 channels, 2000 samples)\")\n\n# Plot Input\nfig, axes = plt.subplots(3, 1, figsize=(10, 6), sharex=True)\naxes[0].plot(time, s1, \"r\")\naxes[0].set_title(\"Target Source (Transients)\")\naxes[1].plot(time, s2, \"k\")\naxes[1].set_title(\"Distractor Source (Smooth 10Hz)\")\naxes[2].plot(time, X[0], \"gray\")\naxes[2].set_title(\"Mixed Sensor Signal (Ch 0)\")\nplt.tight_layout()\nplt.show(block=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Applying the Custom Bias\nWe plug our `GradientTriggerBias` into `DSS`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Running DSS with Custom GradientTriggerBias ---\")\n\n# We want to find the component that has the most energy *during high gradients*\ncustom_bias = GradientTriggerBias(threshold_percentile=95)\n\ndss = DSS(bias=custom_bias, n_components=3)\ndss.fit(X)\nS_est = dss.transform(X)\n\n# Plot Results\nfig, axes = plt.subplots(3, 1, figsize=(10, 6), sharex=True)\naxes[0].plot(time, S_est[0], \"r\")\naxes[0].set_title(\"DSS Component 0 (Biased to Gradients)\")\naxes[1].plot(time, S_est[1], \"k\")\naxes[1].set_title(\"DSS Component 1\")\naxes[2].plot(time, S_est[2], \"b\")\naxes[2].set_title(\"DSS Component 2\")\naxes[-1].set_xlabel(\"Time (s)\")\nplt.suptitle(\"Custom Bias Results\")\nplt.tight_layout()\nplt.show(block=False)\n\n# Check correlation with target\ncorr = np.abs(np.corrcoef(S_est[0], s1)[0, 1])\nprint(f\"Correlation between Component 0 and Target Transients: {corr:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Using function_bias (Functional API)\nFor simpler cases where you just want to weight the covariance matrix by some\nweighting vector `w(t)`, you don't need to subclass. You can use a closure.\n\nConcept: covariance C = sum( w[t] * x[t] * x[t].T )\n\nLet's say we have an auxiliary channel (e.g., a microphone or trigger channel)\nand we want to bias towards times where this channel is active.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Using Functional Approach (Simple Wrapper) ---\")\n\n# Create a dummy \"trigger\" channel that aligns with the spikes\n# In reality, this would be your aux channel.\naux_trigger = np.abs(s1)  # We cheat and use the envelope of s1 as our 'weight'\n\n\n# Define a function wrapper class (since we removed function_bias helper)\nclass FunctionalBias(LinearDenoiser):\n    def __init__(self, weights):\n        self.weights = weights\n\n    def apply(self, data):\n        # Weight the data (sqrt(weights) because Cov = X @ X.T)\n        # But for simpler Power weighting, we just multiply\n        # Ensure weights align\n        return data * self.weights\n\n\ndss_func = DSS(bias=FunctionalBias(aux_trigger), n_components=3)\ndss_func.fit(X)\nS_func = dss_func.transform(X)\n\nfig, ax = plt.subplots(figsize=(10, 3))\nax.plot(time, S_func[0], \"g\")\nax.set_title(\"Functional Bias Result (Weighted by Envelope)\")\nplt.tight_layout()\nprint(\"\\nExample 9 Complete!\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}