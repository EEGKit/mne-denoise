{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# ZapLine: Parameter Tuning and Real Data.\n\nThis tutorial covers:\n1. Parameter exploration (n_remove, nkeep, threshold)\n2. Real MEG data from NoiseTools\n3. Comparing different parameter settings\n\nAuthors: Sina Esmaeili (sina.esmaeili@umontreal.ca)\n         Hamza Abdelhedi (hamza.abdelhedi@umontreal.ca)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import signal\nfrom scipy.io import loadmat\n\nfrom mne_denoise.viz.zapline import (\n    plot_cleaning_summary,\n    plot_component_scores,\n    plot_psd_comparison,\n    plot_spatial_patterns,\n)\nfrom mne_denoise.zapline import ZapLine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: n_remove Parameter\nThe `n_remove` parameter controls how many spatial components are removed.\nToo few: line noise remains. Too many: neural signal lost.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Part 1: Exploring n_remove parameter\")\n\n# Generate synthetic data with multiple line noise sources\nsfreq = 1000\nduration = 5\nn_channels = 16\nn_times = int(sfreq * duration)\nt = np.arange(n_times) / sfreq\n\nrng = np.random.RandomState(42)\n\n# Create 3 distinct line noise sources (simulating multiple power sources)\nn_line_sources = 3\nline_patterns = rng.randn(n_channels, n_line_sources)\nfor i in range(n_line_sources):\n    line_patterns[:, i] /= np.linalg.norm(line_patterns[:, i])\n\n# Neural pattern\nneural_pattern = rng.randn(n_channels)\nneural_pattern /= np.linalg.norm(neural_pattern)\n\n# Generate data\nneural_source = np.sin(2 * np.pi * 10 * t)\nline_sources = np.zeros((n_line_sources, n_times))\nfor i in range(n_line_sources):\n    phase = rng.uniform(0, 2 * np.pi)\n    amp = 2.0 - i * 0.5  # Decreasing amplitude\n    line_sources[i] = amp * np.sin(2 * np.pi * 50 * t + phase)\n\ndata = np.zeros((n_channels, n_times))\nfor i in range(n_channels):\n    data[i] = neural_pattern[i] * neural_source\n    for j in range(n_line_sources):\n        data[i] += line_patterns[i, j] * line_sources[j]\n    data[i] += rng.randn(n_times) * 0.3\n\nprint(f\"Data with {n_line_sources} line noise sources\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare Different n_remove Values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n\nn_remove_values = [1, 2, 3, 4, 5, \"auto\"]\n\nfor idx, n_remove in enumerate(n_remove_values):\n    row, col = idx // 3, idx % 3\n    ax = axes[row, col]\n\n    est = ZapLine(line_freq=50, sfreq=sfreq, n_remove=n_remove)\n    est.fit(data)\n    cleaned = est.transform(data)\n\n    freqs, psd_orig = signal.welch(data, sfreq, nperseg=sfreq)\n    freqs, psd_clean = signal.welch(cleaned, sfreq, nperseg=sfreq)\n\n    ax.semilogy(freqs, np.mean(psd_orig, axis=0), \"b-\", alpha=0.3, label=\"Original\")\n    ax.semilogy(freqs, np.mean(psd_clean, axis=0), \"g-\", label=\"Cleaned\")\n    ax.axvline(50, color=\"r\", linestyle=\"--\", alpha=0.5)\n    ax.set_xlim(0, 100)\n    ax.set_title(f\"n_remove={n_remove} (actual: {est.n_removed_})\")\n    ax.set_xlabel(\"Frequency (Hz)\")\n\n    if col == 0:\n        ax.set_ylabel(\"PSD\")\n    if idx == 0:\n        ax.legend()\n\nplt.suptitle(\"Effect of n_remove Parameter\", fontsize=14)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: nkeep Parameter (High Channel Count)\nFor data with many channels, the optional `nkeep` parameter reduces\ndimensionality before DSS to avoid overfitting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nPart 2: nkeep parameter for high-channel data\")\n\n# Create high-channel-count data\nn_channels_high = 128\ndata_high = np.zeros((n_channels_high, n_times))\n\n# Multiple line sources with different spatial patterns\nn_line_sources = 2\nline_patterns_high = rng.randn(n_channels_high, n_line_sources)\nfor i in range(n_line_sources):\n    line_patterns_high[:, i] /= np.linalg.norm(line_patterns_high[:, i])\n\nneural_pattern_high = rng.randn(n_channels_high)\nneural_pattern_high /= np.linalg.norm(neural_pattern_high)\n\nfor i in range(n_channels_high):\n    data_high[i] = neural_pattern_high[i] * neural_source\n    for j in range(n_line_sources):\n        data_high[i] += line_patterns_high[i, j] * line_sources[j]\n    data_high[i] += rng.randn(n_times) * 0.3\n\nprint(f\"High-channel data: {data_high.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare Different nkeep Values\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n\nnkeep_values = [None, 64, 32, 16]\n\nfor idx, nkeep in enumerate(nkeep_values):\n    ax = axes[idx]\n\n    est_high = ZapLine(line_freq=50, sfreq=sfreq, n_remove=2, nkeep=nkeep)\n    est_high.fit(data_high)\n    cleaned_high = est_high.transform(data_high)\n\n    freqs, psd_orig = signal.welch(data_high, sfreq, nperseg=sfreq)\n    freqs, psd_clean = signal.welch(cleaned_high, sfreq, nperseg=sfreq)\n\n    ax.semilogy(freqs, np.mean(psd_orig, axis=0), \"b-\", alpha=0.3, label=\"Original\")\n    ax.semilogy(freqs, np.mean(psd_clean, axis=0), \"g-\", label=\"Cleaned\")\n    ax.axvline(50, color=\"r\", linestyle=\"--\", alpha=0.5)\n    ax.set_xlim(0, 100)\n    ax.set_title(f\"nkeep={nkeep if nkeep else 'All (128)'}\")\n    ax.set_xlabel(\"Frequency (Hz)\")\n\n    if idx == 0:\n        ax.set_ylabel(\"PSD\")\n        ax.legend()\n\nplt.suptitle(\"Effect of nkeep Parameter (128 channels)\", fontsize=14)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: Component Scores\nThe eigenvalues (scores) indicate how much each component\ncarries line noise. High scores = strong line noise.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nPart 3: Understanding component scores\")\n\nest_scores = ZapLine(line_freq=50, sfreq=sfreq, n_remove=\"auto\")\nest_scores.fit(data)\n\n# Use the reusable viz functions\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\nplot_component_scores(est_scores, ax=axes[0], show=False)\nplot_spatial_patterns(est_scores, n_patterns=3, ax=axes[1], show=False)\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: Real MEG Data (NoiseTools)\nApply ZapLine to real MEG data from NoiseTools dataset.\nData from: http://audition.ens.fr/adc/NoiseTools/DATA/\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nPart 4: Real MEG Data\")\n\n# Find data directory\n# Find data directory - handle both script calculation and gallery execution\ntry:\n    script_dir = Path(__file__).parent\nexcept NameError:\n    script_dir = Path.cwd()\ndata_dir = script_dir / \"data\"\n\n# Load data1.mat (MEG with large near-DC fluctuations)\ndata1_path = data_dir / \"data1.mat\"\nif data1_path.exists():\n    mat = loadmat(str(data1_path))\n    meg_data = mat[\"data\"].T  # Transpose to (channels, times)\n    sfreq_meg = float(mat[\"sr\"].flatten()[0])\n\n    # Demean\n    meg_data = meg_data - np.mean(meg_data, axis=1, keepdims=True)\n\n    print(f\"Loaded data1.mat: {meg_data.shape}, sfreq={sfreq_meg} Hz\")\n    print(\"MEG data with large near-DC fluctuations\")\nelse:\n    print(f\"Data not found: {data1_path}\")\n    print(\"Download from: http://audition.ens.fr/adc/NoiseTools/DATA/data1.mat\")\n    meg_data = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply ZapLine to MEG Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if meg_data is not None:\n    # Apply ZapLine (60 Hz for this dataset)\n    est_meg = ZapLine(\n        line_freq=60,\n        sfreq=sfreq_meg,\n        n_remove=2,  # As in MATLAB example\n    )\n    est_meg.fit(meg_data)\n    cleaned_meg = est_meg.transform(meg_data)\n\n    print(f\"Components removed: {est_meg.n_removed_}\")\n\n    # %%\n    # Compare Before/After for MEG\n    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    # Use reusable viz function for PSD comparison\n    plot_psd_comparison(\n        meg_data, cleaned_meg, sfreq_meg, line_freq=60, fmax=150, show=True\n    )\n\n    # Show comprehensive summary\n    plot_cleaning_summary(\n        meg_data, cleaned_meg, est_meg, sfreq_meg, line_freq=60, show=True\n    )\n\n    # %%\n    # Measure Reduction\n    # ^^^^^^^^^^^^^^^^^\n\n    idx_60 = np.argmin(np.abs(freqs - 60))\n    power_60_orig = np.mean(psd_orig[:, idx_60])\n    power_60_clean = np.mean(psd_clean[:, idx_60])\n    reduction_db = 10 * np.log10(power_60_orig / power_60_clean)\n\n    print(\"\\n=== MEG Results ===\")\n    print(f\"60 Hz power reduction: {reduction_db:.1f} dB\")\n    print(f\"Components removed: {est_meg.n_removed_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\nKey parameter guidelines:\n\n- **n_remove**: Start with \"auto\" or 1-3. Increase if line noise remains.\n- **nkeep**: Use for high-channel data (>64). Try 32-64.\n- **threshold**: For \"auto\" mode. Lower = more aggressive removal.\n- **n_harmonics**: Usually auto-detected. Increase for high sfreq data.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}